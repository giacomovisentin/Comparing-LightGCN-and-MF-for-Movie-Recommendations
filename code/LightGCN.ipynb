{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtPdFNJ6syFI",
        "outputId": "e0d3f5eb-2580-4b27-a543-152c5c072c88"
      },
      "outputs": [],
      "source": [
        "!pip install torch-geometric\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.5.1+cu121.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hUj3Zt55s0nZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "from torch_sparse import SparseTensor\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zG0g4D0gtM7x"
      },
      "outputs": [],
      "source": [
        "def create_bipartite_edge_tensors(df, src_index_column, dst_index_column, link_index_col, rating_threshold=1):\n",
        "    \"\"\"\n",
        "    Parses a CSV file containing edges between users and items\n",
        "    This function provides the basic data to construct a sparse matrix in COO format\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame with edge data.\n",
        "        src_index_column (str): Name of the column representing user IDs.\n",
        "        dst_index_column (str): Name of the column representing item IDs.\n",
        "        link_index_col (str): Name of the column for interaction values (in our case the ratings).\n",
        "        rating_threshold (int, optional): Value to classify edges as positive. Default is 1\n",
        "        (for our case of MSE we need all the ratings, if we want to use other loss we have to change this value)\n",
        "\n",
        "    Returns:\n",
        "        edge_index (torch.Tensor): A 2 x N tensor with source and destination node IDs for N edges.\n",
        "            (edge_index[0] corresponds to the row indices, edge_index[1] corresponds to the column indices)\n",
        "        edge_values (torch.Tensor): A 1D tensor with interaction values corresponding to the edges (the ratings).\n",
        "    \"\"\"\n",
        "    # Extract relevant columns\n",
        "    src = df[src_index_column].values\n",
        "    dst = df[dst_index_column].values\n",
        "    link_vals = df[link_index_col].values\n",
        "\n",
        "    # Apply rating threshold\n",
        "    mask = link_vals >= rating_threshold\n",
        "\n",
        "    # Filter edges based on the mask\n",
        "    src_filtered = src[mask]\n",
        "    dst_filtered = dst[mask]\n",
        "    link_vals_filtered = link_vals[mask]\n",
        "\n",
        "    # Create edge_index and edge_values\n",
        "    edge_index = torch.tensor([src_filtered, dst_filtered], dtype=torch.long)\n",
        "    edge_values = torch.tensor(link_vals_filtered, dtype=torch.long)\n",
        "\n",
        "    return edge_index, edge_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9eT_nzUZtZAp"
      },
      "outputs": [],
      "source": [
        "# R is the user-item interaction matrix\n",
        "# Adj is the Adjacency matrix\n",
        "\n",
        "def r_to_adj_matrix(input_edge_index, input_edge_values, num_users, num_movies):\n",
        "    \"\"\"\n",
        "    Converts edge index and values to an adjacency matrix in COO format.\n",
        "\n",
        "    Args:\n",
        "        input_edge_index (torch.Tensor): 2 x N tensor with source and destination indices.\n",
        "        input_edge_values (torch.Tensor): 1D tensor with edge weights/values.\n",
        "        num_users (int): Number of user nodes.\n",
        "        num_movies (int): Number of movie nodes.\n",
        "\n",
        "    Returns:\n",
        "        adj_mat_coo_indices (torch.Tensor): 2 x M tensor with COO format indices.\n",
        "        adj_mat_coo_values (torch.Tensor): 1D tensor with corresponding values.\n",
        "    \"\"\"\n",
        "    # Initialize R matrix with sparse representation\n",
        "    R = torch.sparse_coo_tensor(\n",
        "        indices=input_edge_index,\n",
        "        values=input_edge_values,\n",
        "        size=(num_users, num_movies)\n",
        "    ).to_dense()\n",
        "\n",
        "    # Transpose R to create R_transpose\n",
        "    R_transpose = R.T\n",
        "\n",
        "    # Create adjacency matrix in dense format\n",
        "    adj_mat = torch.zeros((num_users + num_movies, num_users + num_movies), dtype=torch.float32)\n",
        "    adj_mat[:num_users, num_users:] = R\n",
        "    adj_mat[num_users:, :num_users] = R_transpose\n",
        "\n",
        "    # Convert adjacency matrix to sparse COO format\n",
        "    adj_mat_coo = adj_mat.to_sparse()\n",
        "    adj_mat_coo_indices = adj_mat_coo.indices()\n",
        "    adj_mat_coo_values = adj_mat_coo.values()\n",
        "\n",
        "    return adj_mat_coo_indices, adj_mat_coo_values\n",
        "\n",
        "\n",
        "def adj_to_r_matrix(input_edge_index, input_edge_values, num_users, num_movies):\n",
        "    \"\"\"\n",
        "    Converts an adjacency matrix edge index and values to a user-item interaction matrix (R) in COO format.\n",
        "\n",
        "    Args:\n",
        "        input_edge_index (torch.Tensor): 2 x N tensor with source and destination indices.\n",
        "        input_edge_values (torch.Tensor): 1D tensor with edge weights/values.\n",
        "        num_users (int): Number of user nodes.\n",
        "        num_movies (int): Number of movie nodes.\n",
        "\n",
        "    Returns:\n",
        "        r_matrix_indices (torch.Tensor): 2 x M tensor with COO format indices for the user-item interaction matrix.\n",
        "        r_matrix_values (torch.Tensor): 1D tensor with corresponding values for the user-item interaction matrix.\n",
        "    \"\"\"\n",
        "    # Create sparse adjacency matrix\n",
        "    sparse_adj = SparseTensor(\n",
        "        row=input_edge_index[0],\n",
        "        col=input_edge_index[1],\n",
        "        value=input_edge_values,\n",
        "        sparse_sizes=(num_users + num_movies, num_users + num_movies)\n",
        "    )\n",
        "\n",
        "    # Convert to dense adjacency matrix\n",
        "    adj_mat = sparse_adj.to_dense()\n",
        "\n",
        "    # Extract the interaction matrix (R)\n",
        "    interact_mat = adj_mat[:num_users, num_users:]\n",
        "\n",
        "    # Convert interaction matrix to sparse COO format\n",
        "    interact_mat_coo = interact_mat.to_sparse()\n",
        "    r_matrix_indices = interact_mat_coo.indices()\n",
        "    r_matrix_values = interact_mat_coo.values()\n",
        "\n",
        "    return r_matrix_indices, r_matrix_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "EUY84uUIvZ2_"
      },
      "outputs": [],
      "source": [
        "# LightGCN model \n",
        "class LightGCN(MessagePassing):\n",
        "   def __init__(self, num_users, num_items, embedding_dim=64, K=3):\n",
        "       \"\"\"\n",
        "       Initialize a LightGCN model for collaborative filtering.\n",
        "\n",
        "       Parameters:\n",
        "           num_users: Total number of users in the system\n",
        "           num_items: Total number of items in the system  \n",
        "           embedding_dim: Size of the embedding vectors (default: 64)\n",
        "           K: Number of message passing layers (default: 3)\n",
        "       \"\"\"\n",
        "       super().__init__()\n",
        "       self.num_users, self.num_items = num_users, num_items\n",
        "       self.embedding_dim, self.K = embedding_dim, K\n",
        "\n",
        "       # Initialize embeddings for users and items with random normal distribution\n",
        "       self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim)  \n",
        "       self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim)\n",
        "       nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "       nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "       # Final linear layer to produce ratings\n",
        "       self.out = nn.Linear(embedding_dim * 2, 1)\n",
        "\n",
        "   def forward(self, edge_index: Tensor, edge_values: Tensor, num_users, num_movies):\n",
        "       \"\"\"\n",
        "       Forward pass of the LightGCN model.\n",
        "       \n",
        "       Args:\n",
        "           edge_index: Sparse adjacency matrix representing user-item interactions\n",
        "           edge_values: Values/weights of the interactions\n",
        "           num_users: Number of users\n",
        "           num_movies: Number of movies/items\n",
        "       \"\"\"\n",
        "       # Normalize adjacency matrix\n",
        "       edge_index_norm = gcn_norm(edge_index, add_self_loops=False)\n",
        "\n",
        "       # Initialize embeddings for layer 0\n",
        "       emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight])  \n",
        "       embs = [emb_0]\n",
        "       emb_k = emb_0\n",
        "\n",
        "       # Perform K iterations of message passing\n",
        "       for i in range(self.K):\n",
        "           emb_k = self.propagate(edge_index=edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n",
        "           embs.append(emb_k)\n",
        "\n",
        "       # Aggregate embeddings from all layers\n",
        "       embs = torch.stack(embs, dim=1)\n",
        "       emb_final = torch.mean(embs, dim=1)\n",
        "\n",
        "       # Split aggregated embeddings back into user and item embeddings\n",
        "       users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items])\n",
        "\n",
        "       r_mat_edge_index, _ = adj_to_r_matrix(edge_index, edge_values, num_users, num_movies)\n",
        "       scr, dst = r_mat_edge_index[0], r_mat_edge_index[1]\n",
        "       users_emb = users_emb_final[scr]\n",
        "       items_emb = items_emb_final[dst]\n",
        "\n",
        "       # Generate final predictions\n",
        "       output = torch.cat([users_emb, items_emb], dim=1)\n",
        "       output = self.out(output)\n",
        "       return output\n",
        "\n",
        "   def message(self, x_j, norm):\n",
        "       \"\"\"\n",
        "       Message passing operation for graph convolution.\n",
        "       \"\"\"\n",
        "       return norm.view(-1, 1) * x_j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "def get_recommendation_metrics(input_edge_index, input_edge_values, pred_ratings, num_movies, k=10, threshold=3.5):\n",
        "    \"\"\"\n",
        "    Calculate various recommendation metrics including Recall, Precision, Gini Index and Coverage.\n",
        "\n",
        "    Args:\n",
        "        input_edge_index (Tensor): Edge indices\n",
        "        input_edge_values (Tensor): True ratings\n",
        "        pred_ratings (Tensor): Predicted ratings\n",
        "        k (int): Number of top items to consider\n",
        "        threshold (float): Rating threshold for relevant items\n",
        "\n",
        "    Returns:\n",
        "        tuple: Recall, Precision, Gini Index, Coverage\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        user_item_rating_list = defaultdict(list)\n",
        "        item_recommendation_count = defaultdict(int)\n",
        "        total_recommendations = 0\n",
        "        unique_items = set()\n",
        "\n",
        "        # Organize predictions by user\n",
        "        for i in range(len(input_edge_index[0])):\n",
        "            src = input_edge_index[0][i].item()\n",
        "            dst = input_edge_index[1][i].item()\n",
        "            true_rating = input_edge_values[i].item()\n",
        "            pred_rating = pred_ratings[i].item()\n",
        "            user_item_rating_list[src].append((pred_rating, true_rating, dst))\n",
        "            unique_items.add(dst)\n",
        "\n",
        "        # Calculate recall and precision, track recommended items\n",
        "        recall = dict()\n",
        "        precision = dict()\n",
        "\n",
        "        for user_id, user_ratings in user_item_rating_list.items():\n",
        "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "            top_k_items = user_ratings[:k]\n",
        "\n",
        "            # Count recommendations per item\n",
        "            for _, _, item_id in top_k_items:\n",
        "                item_recommendation_count[item_id] += 1\n",
        "                total_recommendations += 1\n",
        "\n",
        "            n_rel = sum((true_r >= threshold) for (_, true_r, _) in user_ratings)\n",
        "            n_rec_k = sum((est_r >= threshold) for (est_r, _, _) in top_k_items)\n",
        "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est_r >= threshold))\n",
        "                                for (est_r, true_r, _) in top_k_items)\n",
        "\n",
        "            recall[user_id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "            precision[user_id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "\n",
        "        # Calculate Gini Index\n",
        "        proportions = []\n",
        "        for item in unique_items:\n",
        "            count = item_recommendation_count.get(item, 0)\n",
        "            proportion = count / total_recommendations if total_recommendations > 0 else 0\n",
        "            proportions.append(proportion)\n",
        "\n",
        "        proportions.sort()\n",
        "        n = len(proportions)\n",
        "        gini = 0\n",
        "        for i, proportion in enumerate(proportions):\n",
        "            gini += (2 * (i + 1) - n - 1) * proportion\n",
        "        gini = gini / (n - 1) if n > 1 else 0\n",
        "\n",
        "        # Calculate Coverage\n",
        "        recommended_items = len([x for x in item_recommendation_count.values() if x > 0])\n",
        "        coverage = recommended_items / num_movies if num_movies > 0 else 0\n",
        "\n",
        "        overall_recall = sum(rec for rec in recall.values()) / len(recall)\n",
        "        overall_precision = sum(prec for prec in precision.values()) / len(precision)\n",
        "\n",
        "        return overall_recall, overall_precision, gini, coverage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **100K Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "rating_path = \"\" # insert here the path of 'ratings.csv' dataset\n",
        "\n",
        "rating_df = pd.read_csv(rating_path, delimiter='\\t', header=None)\n",
        "rating_df.columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
        "\n",
        "lbl_user = preprocessing.LabelEncoder( )\n",
        "lbl_movie = preprocessing.LabelEncoder( )\n",
        "\n",
        "rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n",
        "rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)\n",
        "\n",
        "num_users = len(rating_df['userId'].unique())\n",
        "num_movies = len(rating_df['movieId'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 x 100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_9587/3627682656.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  edge_values = torch.tensor(edge_values)\n"
          ]
        }
      ],
      "source": [
        "edge_index, edge_values = create_bipartite_edge_tensors(rating_df, 'userId', 'movieId', 'rating')\n",
        "print(f\"{len(edge_index)} x {len(edge_index[0])}\")\n",
        "\n",
        "edge_index = torch.LongTensor(edge_index)\n",
        "edge_values = torch.tensor(edge_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_interactions = edge_index.shape[1]\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "train_indices, test_indices = train_test_split(all_indices, test_size=0.2, random_state=1)\n",
        "val_indices, test_indices = train_test_split(test_indices, test_size=0.5, random_state=1)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "train_edge_value = edge_values[train_indices]\n",
        "\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "val_edge_value = edge_values[val_indices]\n",
        "\n",
        "test_edge_index = edge_index[:, test_indices]\n",
        "test_edge_value = edge_values[test_indices]\n",
        "\n",
        "\n",
        "# Create Adj matrix in COO format\n",
        "train_edge_index, train_edge_values = r_to_adj_matrix(train_edge_index, train_edge_value, num_users, num_movies)\n",
        "val_edge_index, val_edge_values = r_to_adj_matrix(val_edge_index, val_edge_value, num_users, num_movies)\n",
        "test_edge_index, test_edge_values = r_to_adj_matrix(test_edge_index, test_edge_value, num_users, num_movies)\n",
        "\n",
        "# Create R matrix in COO format (from the Adj matrix in COO format)\n",
        "r_mat_train_edge_index, r_mat_train_edge_values = adj_to_r_matrix(train_edge_index, train_edge_values, num_users, num_movies)\n",
        "r_mat_val_edge_index, r_mat_val_edge_values = adj_to_r_matrix(val_edge_index, val_edge_values, num_users, num_movies)\n",
        "r_mat_test_edge_index, r_mat_test_edge_values = adj_to_r_matrix(test_edge_index, test_edge_values, num_users, num_movies) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "IhqWGj1QwWLr"
      },
      "outputs": [],
      "source": [
        "model = LightGCN(num_users, num_movies)\n",
        "\n",
        "ITERATIONS = 25000\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "N_ELEMENTS_REC = 10\n",
        "\n",
        "model.train()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "loss_function = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tslPYw5fy7xP",
        "outputId": "e1663049-bab4-4052-a59b-672644fc6b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "model = model.to(device)\n",
        "\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_edge_values = train_edge_values.to(device)\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_edge_values = val_edge_values.to(device)\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_edge_values = test_edge_values.to(device)\n",
        "\n",
        "r_mat_train_edge_index = r_mat_train_edge_index.to(device)\n",
        "r_mat_train_edge_values = r_mat_train_edge_values.to(device)\n",
        "r_mat_val_edge_index = r_mat_val_edge_index.to(device)\n",
        "r_mat_val_edge_values = r_mat_val_edge_values.to(device)\n",
        "r_mat_test_edge_index = r_mat_test_edge_index.to(device)\n",
        "r_mat_test_edge_values = r_mat_test_edge_values.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxBVLClMU5sy",
        "outputId": "6fd25b38-47de-464d-886b-b7449ba23dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 0/25000, Train loss: 14.1444, Val loss: 14.2225, Recall: 0.0000, Precision: 0.0000, Gini: 0.6252, Coverage: 0.5922\n",
            "Iter 200/25000, Train loss: 2.3885, Val loss: 2.3656, Recall: 0.0259, Precision: 0.1499, Gini: 0.7457, Coverage: 0.4673\n",
            "Iter 400/25000, Train loss: 1.7089, Val loss: 1.6842, Recall: 0.1130, Precision: 0.3223, Gini: 0.7459, Coverage: 0.4667\n",
            "Iter 600/25000, Train loss: 1.5281, Val loss: 1.5029, Recall: 0.1629, Precision: 0.3767, Gini: 0.7457, Coverage: 0.4679\n",
            "Iter 800/25000, Train loss: 1.4335, Val loss: 1.4089, Recall: 0.1923, Precision: 0.3993, Gini: 0.7455, Coverage: 0.4679\n",
            "Iter 1000/25000, Train loss: 1.3715, Val loss: 1.3479, Recall: 0.2159, Precision: 0.4223, Gini: 0.7450, Coverage: 0.4679\n",
            "Iter 1200/25000, Train loss: 1.3262, Val loss: 1.3039, Recall: 0.2320, Precision: 0.4416, Gini: 0.7449, Coverage: 0.4679\n",
            "Iter 1400/25000, Train loss: 1.2909, Val loss: 1.2699, Recall: 0.2420, Precision: 0.4513, Gini: 0.7446, Coverage: 0.4667\n",
            "Iter 1600/25000, Train loss: 1.2624, Val loss: 1.2425, Recall: 0.2548, Precision: 0.4593, Gini: 0.7444, Coverage: 0.4667\n",
            "Iter 1800/25000, Train loss: 1.2386, Val loss: 1.2199, Recall: 0.2621, Precision: 0.4629, Gini: 0.7441, Coverage: 0.4673\n",
            "Iter 2000/25000, Train loss: 1.2184, Val loss: 1.2008, Recall: 0.2702, Precision: 0.4727, Gini: 0.7440, Coverage: 0.4667\n",
            "Iter 2200/25000, Train loss: 1.2011, Val loss: 1.1843, Recall: 0.2735, Precision: 0.4750, Gini: 0.7438, Coverage: 0.4661\n",
            "Iter 2400/25000, Train loss: 1.1859, Val loss: 1.1700, Recall: 0.2795, Precision: 0.4795, Gini: 0.7432, Coverage: 0.4661\n",
            "Iter 2600/25000, Train loss: 1.1725, Val loss: 1.1574, Recall: 0.2844, Precision: 0.4818, Gini: 0.7431, Coverage: 0.4661\n",
            "Iter 2800/25000, Train loss: 1.1607, Val loss: 1.1462, Recall: 0.2896, Precision: 0.4844, Gini: 0.7427, Coverage: 0.4661\n",
            "Iter 3000/25000, Train loss: 1.1502, Val loss: 1.1362, Recall: 0.2949, Precision: 0.4896, Gini: 0.7424, Coverage: 0.4661\n",
            "Iter 3200/25000, Train loss: 1.1408, Val loss: 1.1272, Recall: 0.3004, Precision: 0.4923, Gini: 0.7422, Coverage: 0.4661\n",
            "Iter 3400/25000, Train loss: 1.1323, Val loss: 1.1191, Recall: 0.3052, Precision: 0.4965, Gini: 0.7421, Coverage: 0.4661\n",
            "Iter 3600/25000, Train loss: 1.1248, Val loss: 1.1118, Recall: 0.3109, Precision: 0.5031, Gini: 0.7420, Coverage: 0.4661\n",
            "Iter 3800/25000, Train loss: 1.1180, Val loss: 1.1052, Recall: 0.3138, Precision: 0.5051, Gini: 0.7415, Coverage: 0.4673\n",
            "Iter 4000/25000, Train loss: 1.1119, Val loss: 1.0993, Recall: 0.3168, Precision: 0.5067, Gini: 0.7414, Coverage: 0.4673\n",
            "Iter 4200/25000, Train loss: 1.1064, Val loss: 1.0939, Recall: 0.3184, Precision: 0.5058, Gini: 0.7412, Coverage: 0.4673\n",
            "Iter 4400/25000, Train loss: 1.1015, Val loss: 1.0890, Recall: 0.3207, Precision: 0.5085, Gini: 0.7409, Coverage: 0.4685\n",
            "Iter 4600/25000, Train loss: 1.0971, Val loss: 1.0847, Recall: 0.3222, Precision: 0.5088, Gini: 0.7406, Coverage: 0.4691\n",
            "Iter 4800/25000, Train loss: 1.0932, Val loss: 1.0807, Recall: 0.3254, Precision: 0.5129, Gini: 0.7405, Coverage: 0.4697\n",
            "Iter 5000/25000, Train loss: 1.0898, Val loss: 1.0772, Recall: 0.3265, Precision: 0.5142, Gini: 0.7404, Coverage: 0.4697\n",
            "Iter 5200/25000, Train loss: 1.0867, Val loss: 1.0740, Recall: 0.3276, Precision: 0.5154, Gini: 0.7403, Coverage: 0.4697\n",
            "Iter 5400/25000, Train loss: 1.0841, Val loss: 1.0712, Recall: 0.3293, Precision: 0.5179, Gini: 0.7401, Coverage: 0.4703\n",
            "Iter 5600/25000, Train loss: 1.0817, Val loss: 1.0686, Recall: 0.3303, Precision: 0.5165, Gini: 0.7398, Coverage: 0.4703\n",
            "Iter 5800/25000, Train loss: 1.0796, Val loss: 1.0664, Recall: 0.3306, Precision: 0.5164, Gini: 0.7398, Coverage: 0.4703\n",
            "Iter 6000/25000, Train loss: 1.0778, Val loss: 1.0644, Recall: 0.3314, Precision: 0.5164, Gini: 0.7397, Coverage: 0.4703\n",
            "Iter 6200/25000, Train loss: 1.0763, Val loss: 1.0627, Recall: 0.3316, Precision: 0.5152, Gini: 0.7397, Coverage: 0.4703\n",
            "Iter 6400/25000, Train loss: 1.0750, Val loss: 1.0611, Recall: 0.3322, Precision: 0.5158, Gini: 0.7395, Coverage: 0.4703\n",
            "Iter 6600/25000, Train loss: 1.0738, Val loss: 1.0598, Recall: 0.3323, Precision: 0.5157, Gini: 0.7393, Coverage: 0.4703\n",
            "Iter 6800/25000, Train loss: 1.0728, Val loss: 1.0586, Recall: 0.3328, Precision: 0.5165, Gini: 0.7392, Coverage: 0.4703\n",
            "Iter 7000/25000, Train loss: 1.0719, Val loss: 1.0576, Recall: 0.3332, Precision: 0.5166, Gini: 0.7391, Coverage: 0.4703\n",
            "Iter 7200/25000, Train loss: 1.0712, Val loss: 1.0567, Recall: 0.3339, Precision: 0.5171, Gini: 0.7390, Coverage: 0.4703\n",
            "Iter 7400/25000, Train loss: 1.0706, Val loss: 1.0559, Recall: 0.3348, Precision: 0.5181, Gini: 0.7390, Coverage: 0.4703\n",
            "Iter 7600/25000, Train loss: 1.0700, Val loss: 1.0551, Recall: 0.3363, Precision: 0.5191, Gini: 0.7388, Coverage: 0.4709\n",
            "Iter 7800/25000, Train loss: 1.0696, Val loss: 1.0545, Recall: 0.3368, Precision: 0.5190, Gini: 0.7389, Coverage: 0.4709\n",
            "Iter 8000/25000, Train loss: 1.0691, Val loss: 1.0540, Recall: 0.3383, Precision: 0.5201, Gini: 0.7389, Coverage: 0.4709\n",
            "Iter 8200/25000, Train loss: 1.0688, Val loss: 1.0535, Recall: 0.3405, Precision: 0.5222, Gini: 0.7388, Coverage: 0.4709\n",
            "Iter 8400/25000, Train loss: 1.0685, Val loss: 1.0531, Recall: 0.3410, Precision: 0.5234, Gini: 0.7387, Coverage: 0.4709\n",
            "Iter 8600/25000, Train loss: 1.0682, Val loss: 1.0527, Recall: 0.3415, Precision: 0.5239, Gini: 0.7387, Coverage: 0.4709\n",
            "Iter 8800/25000, Train loss: 1.0680, Val loss: 1.0523, Recall: 0.3417, Precision: 0.5238, Gini: 0.7385, Coverage: 0.4709\n",
            "Iter 9000/25000, Train loss: 1.0678, Val loss: 1.0520, Recall: 0.3426, Precision: 0.5250, Gini: 0.7385, Coverage: 0.4709\n",
            "Iter 9200/25000, Train loss: 1.0676, Val loss: 1.0518, Recall: 0.3432, Precision: 0.5239, Gini: 0.7385, Coverage: 0.4709\n",
            "Iter 9400/25000, Train loss: 1.0674, Val loss: 1.0515, Recall: 0.3453, Precision: 0.5256, Gini: 0.7382, Coverage: 0.4709\n",
            "Iter 9600/25000, Train loss: 1.0673, Val loss: 1.0513, Recall: 0.3452, Precision: 0.5254, Gini: 0.7382, Coverage: 0.4709\n",
            "Iter 9800/25000, Train loss: 1.0672, Val loss: 1.0511, Recall: 0.3460, Precision: 0.5261, Gini: 0.7381, Coverage: 0.4709\n",
            "Iter 10000/25000, Train loss: 1.0671, Val loss: 1.0509, Recall: 0.3473, Precision: 0.5272, Gini: 0.7381, Coverage: 0.4709\n",
            "Iter 10200/25000, Train loss: 1.0670, Val loss: 1.0508, Recall: 0.3472, Precision: 0.5273, Gini: 0.7381, Coverage: 0.4709\n",
            "Iter 10400/25000, Train loss: 1.0669, Val loss: 1.0506, Recall: 0.3482, Precision: 0.5277, Gini: 0.7379, Coverage: 0.4709\n",
            "Iter 10600/25000, Train loss: 1.0668, Val loss: 1.0505, Recall: 0.3482, Precision: 0.5266, Gini: 0.7379, Coverage: 0.4709\n",
            "Iter 10800/25000, Train loss: 1.0668, Val loss: 1.0504, Recall: 0.3483, Precision: 0.5265, Gini: 0.7378, Coverage: 0.4709\n",
            "Iter 11000/25000, Train loss: 1.0667, Val loss: 1.0503, Recall: 0.3482, Precision: 0.5265, Gini: 0.7377, Coverage: 0.4709\n",
            "Iter 11200/25000, Train loss: 1.0667, Val loss: 1.0502, Recall: 0.3485, Precision: 0.5263, Gini: 0.7376, Coverage: 0.4709\n",
            "Iter 11400/25000, Train loss: 1.0666, Val loss: 1.0501, Recall: 0.3491, Precision: 0.5259, Gini: 0.7376, Coverage: 0.4709\n",
            "Iter 11600/25000, Train loss: 1.0666, Val loss: 1.0500, Recall: 0.3496, Precision: 0.5261, Gini: 0.7375, Coverage: 0.4709\n",
            "Iter 11800/25000, Train loss: 1.0666, Val loss: 1.0499, Recall: 0.3501, Precision: 0.5257, Gini: 0.7375, Coverage: 0.4709\n",
            "Iter 12000/25000, Train loss: 1.0666, Val loss: 1.0499, Recall: 0.3506, Precision: 0.5269, Gini: 0.7375, Coverage: 0.4709\n",
            "Iter 12200/25000, Train loss: 1.0666, Val loss: 1.0498, Recall: 0.3508, Precision: 0.5273, Gini: 0.7374, Coverage: 0.4715\n",
            "Iter 12400/25000, Train loss: 1.0665, Val loss: 1.0498, Recall: 0.3517, Precision: 0.5268, Gini: 0.7373, Coverage: 0.4715\n",
            "Iter 12600/25000, Train loss: 1.0665, Val loss: 1.0497, Recall: 0.3529, Precision: 0.5279, Gini: 0.7373, Coverage: 0.4715\n",
            "Iter 12800/25000, Train loss: 1.0665, Val loss: 1.0497, Recall: 0.3528, Precision: 0.5276, Gini: 0.7373, Coverage: 0.4715\n",
            "Iter 13000/25000, Train loss: 1.0665, Val loss: 1.0496, Recall: 0.3528, Precision: 0.5276, Gini: 0.7373, Coverage: 0.4715\n",
            "Iter 13200/25000, Train loss: 1.0665, Val loss: 1.0496, Recall: 0.3527, Precision: 0.5276, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 13400/25000, Train loss: 1.0665, Val loss: 1.0496, Recall: 0.3527, Precision: 0.5276, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 13600/25000, Train loss: 1.0665, Val loss: 1.0496, Recall: 0.3525, Precision: 0.5274, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 13800/25000, Train loss: 1.0665, Val loss: 1.0495, Recall: 0.3526, Precision: 0.5274, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 14000/25000, Train loss: 1.0665, Val loss: 1.0495, Recall: 0.3524, Precision: 0.5274, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 14200/25000, Train loss: 1.0665, Val loss: 1.0495, Recall: 0.3526, Precision: 0.5270, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 14400/25000, Train loss: 1.0665, Val loss: 1.0495, Recall: 0.3529, Precision: 0.5270, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 14600/25000, Train loss: 1.0665, Val loss: 1.0495, Recall: 0.3528, Precision: 0.5270, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 14800/25000, Train loss: 1.0666, Val loss: 1.0495, Recall: 0.3528, Precision: 0.5268, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 15000/25000, Train loss: 1.0666, Val loss: 1.0494, Recall: 0.3539, Precision: 0.5275, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 15200/25000, Train loss: 1.0666, Val loss: 1.0494, Recall: 0.3544, Precision: 0.5275, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 15400/25000, Train loss: 1.0666, Val loss: 1.0494, Recall: 0.3545, Precision: 0.5275, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 15600/25000, Train loss: 1.0666, Val loss: 1.0494, Recall: 0.3545, Precision: 0.5275, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 15800/25000, Train loss: 1.0666, Val loss: 1.0494, Recall: 0.3544, Precision: 0.5271, Gini: 0.7372, Coverage: 0.4715\n",
            "Iter 16000/25000, Train loss: 1.0666, Val loss: 1.0494, Recall: 0.3546, Precision: 0.5271, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 16200/25000, Train loss: 1.0666, Val loss: 1.0494, Recall: 0.3546, Precision: 0.5271, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 16400/25000, Train loss: 1.0666, Val loss: 1.0494, Recall: 0.3545, Precision: 0.5264, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 16600/25000, Train loss: 1.0666, Val loss: 1.0494, Recall: 0.3554, Precision: 0.5287, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 16800/25000, Train loss: 1.0666, Val loss: 1.0494, Recall: 0.3554, Precision: 0.5287, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 17000/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3560, Precision: 0.5289, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 17200/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3572, Precision: 0.5299, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 17400/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3576, Precision: 0.5299, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 17600/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3575, Precision: 0.5299, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 17800/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3576, Precision: 0.5300, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 18000/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3576, Precision: 0.5300, Gini: 0.7370, Coverage: 0.4715\n",
            "Iter 18200/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3580, Precision: 0.5300, Gini: 0.7370, Coverage: 0.4715\n",
            "Iter 18400/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3591, Precision: 0.5310, Gini: 0.7370, Coverage: 0.4715\n",
            "Iter 18600/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3591, Precision: 0.5309, Gini: 0.7370, Coverage: 0.4715\n",
            "Iter 18800/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3596, Precision: 0.5331, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 19000/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3598, Precision: 0.5331, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 19200/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3598, Precision: 0.5331, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 19400/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3600, Precision: 0.5331, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 19600/25000, Train loss: 1.0667, Val loss: 1.0494, Recall: 0.3599, Precision: 0.5331, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 19800/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3599, Precision: 0.5331, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 20000/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3599, Precision: 0.5331, Gini: 0.7371, Coverage: 0.4715\n",
            "Iter 20200/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3599, Precision: 0.5331, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 20400/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3599, Precision: 0.5331, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 20600/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3599, Precision: 0.5331, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 20800/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3599, Precision: 0.5331, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 21000/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3601, Precision: 0.5337, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 21200/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3601, Precision: 0.5337, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 21400/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3601, Precision: 0.5337, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 21600/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3601, Precision: 0.5337, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 21800/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3601, Precision: 0.5337, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 22000/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3601, Precision: 0.5337, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 22200/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3601, Precision: 0.5337, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 22400/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3600, Precision: 0.5337, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 22600/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3600, Precision: 0.5337, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 22800/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 23000/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 23200/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 23400/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 23600/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 23800/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 24000/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 24200/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 24400/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 24600/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n",
            "Iter 24800/25000, Train loss: 1.0668, Val loss: 1.0494, Recall: 0.3609, Precision: 0.5358, Gini: 0.7369, Coverage: 0.4715\n"
          ]
        }
      ],
      "source": [
        "for iter in range(ITERATIONS):\n",
        "    # FORWARD PASS\n",
        "    pred_ratings = model(train_edge_index, train_edge_values, num_users, num_movies)\n",
        "    train_loss = loss_function(pred_ratings, r_mat_train_edge_values.view(-1, 1))\n",
        "\n",
        "    # BACKWARD PASS\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # VALIDATION SET\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred_ratings = model(val_edge_index, val_edge_values, num_users, num_movies)\n",
        "            val_loss = loss_function(pred_ratings, r_mat_val_edge_values.view(-1, 1)).sum()\n",
        "\n",
        "            recall, precision, gini, coverage = get_recommendation_metrics(\n",
        "                r_mat_val_edge_index, r_mat_val_edge_values, pred_ratings, num_movies, k=N_ELEMENTS_REC\n",
        "            )\n",
        "            print(\n",
        "                f\"Iter {iter}/{ITERATIONS}, Train loss: {train_loss.item():.4f}, \"\n",
        "                f\"Val loss: {val_loss.item():.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Gini: {gini:.4f}, Coverage: {coverage:.4f}\"\n",
        "            )\n",
        "            model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka-aJFe7-XdM",
        "outputId": "9e34bd7e-2b4c-480e-ee6f-c9d6dba040c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test metrics:\n",
            "Loss: 1.0631\n",
            "Recall: 0.3539\n",
            "Precision: 0.5324\n",
            "Gini Index: 0.7512\n",
            "Coverage: 0.4608\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_ratings = model.forward(test_edge_index, test_edge_values, num_users, num_movies)\n",
        "    test_loss = loss_function(pred_ratings, r_mat_test_edge_values.view(-1, 1))\n",
        "    recall, precision, gini, coverage = get_recommendation_metrics(\n",
        "        r_mat_test_edge_index, r_mat_test_edge_values, pred_ratings, num_movies, k=N_ELEMENTS_REC\n",
        "    )\n",
        "    print(f\"Test metrics:\\nLoss: {test_loss.item():.4f}\\nRecall: {recall:.4f}\\n\"\n",
        "          f\"Precision: {precision:.4f}\\nGini Index: {gini:.4f}\\nCoverage: {coverage:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aoUI1uIbeum"
      },
      "source": [
        "# **1M Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "9RomguNlaWcl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_9587/2039882769.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  rating_df = pd.read_csv(rating_path, delimiter='::', header=None)\n"
          ]
        }
      ],
      "source": [
        "rating_path = \"\" # insert here the path of 'ratings.csv' dataset\n",
        "\n",
        "rating_df = pd.read_csv(rating_path, delimiter='::', header=None)\n",
        "rating_df.columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
        "\n",
        "lbl_user = preprocessing.LabelEncoder( )\n",
        "lbl_movie = preprocessing.LabelEncoder( )\n",
        "\n",
        "rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n",
        "rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)\n",
        "\n",
        "num_users = len(rating_df['userId'].unique())\n",
        "num_movies = len(rating_df['movieId'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "78DEcMfCbPUX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 x 1000209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_9587/3627682656.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  edge_values = torch.tensor(edge_values)\n"
          ]
        }
      ],
      "source": [
        "edge_index, edge_values = create_bipartite_edge_tensors(rating_df, 'userId', 'movieId', 'rating')\n",
        "print(f\"{len(edge_index)} x {len(edge_index[0])}\")\n",
        "\n",
        "edge_index = torch.LongTensor(edge_index)\n",
        "edge_values = torch.tensor(edge_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "DMpKFHFtbmFR"
      },
      "outputs": [],
      "source": [
        "num_interactions = edge_index.shape[1]\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "train_indices, test_indices = train_test_split(all_indices, test_size=0.2, random_state=1)\n",
        "val_indices, test_indices = train_test_split(test_indices, test_size=0.5, random_state=1)\n",
        "\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "train_edge_value = edge_values[train_indices]\n",
        "\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "val_edge_value = edge_values[val_indices]\n",
        "\n",
        "test_edge_index = edge_index[:, test_indices]\n",
        "test_edge_value = edge_values[test_indices]\n",
        "\n",
        "\n",
        "train_edge_index, train_edge_values = r_to_adj_matrix(train_edge_index, train_edge_value, num_users, num_movies)\n",
        "val_edge_index, val_edge_values = r_to_adj_matrix(val_edge_index, val_edge_value, num_users, num_movies)\n",
        "test_edge_index, test_edge_values = r_to_adj_matrix(test_edge_index, test_edge_value, num_users, num_movies)\n",
        "\n",
        "r_mat_train_edge_index, r_mat_train_edge_values = adj_to_r_matrix(train_edge_index, train_edge_values, num_users, num_movies)\n",
        "r_mat_val_edge_index, r_mat_val_edge_values = adj_to_r_matrix(val_edge_index, val_edge_values, num_users, num_movies)\n",
        "r_mat_test_edge_index, r_mat_test_edge_values = adj_to_r_matrix(test_edge_index, test_edge_values, num_users, num_movies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "SWa8BbIpb1Mn"
      },
      "outputs": [],
      "source": [
        "model = LightGCN(num_users, num_movies)\n",
        "\n",
        "ITERATIONS = 10000\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "N_ELEMENTS_REC = 10\n",
        "\n",
        "model.train()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "loss_function = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOrBqfsEb1R5",
        "outputId": "a8383fc8-400b-47a8-d488-8f75bac8b9fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_edge_values = train_edge_values.to(device)\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_edge_values = val_edge_values.to(device)\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_edge_values = test_edge_values.to(device)\n",
        "\n",
        "r_mat_train_edge_index = r_mat_train_edge_index.to(device)\n",
        "r_mat_train_edge_values = r_mat_train_edge_values.to(device)\n",
        "r_mat_val_edge_index = r_mat_val_edge_index.to(device)\n",
        "r_mat_val_edge_values = r_mat_val_edge_values.to(device)\n",
        "r_mat_test_edge_index = r_mat_test_edge_index.to(device)\n",
        "r_mat_test_edge_values = r_mat_test_edge_values.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PtwXQ2R5b1Xu",
        "outputId": "1db9b6ef-d77f-424c-c79e-d57e305f081d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 0/10000, Train loss: 13.5167, Val loss: 13.5193, Recall: 0.0000, Precision: 0.0000, Gini: 0.7184, Coverage: 0.7407\n",
            "Iter 200/10000, Train loss: 4.0989, Val loss: 4.0721, Recall: 0.0002, Precision: 0.0054, Gini: 0.8286, Coverage: 0.6317\n",
            "Iter 400/10000, Train loss: 2.2994, Val loss: 2.2912, Recall: 0.0655, Precision: 0.3476, Gini: 0.8286, Coverage: 0.6309\n",
            "Iter 600/10000, Train loss: 1.9006, Val loss: 1.8940, Recall: 0.1297, Precision: 0.4678, Gini: 0.8284, Coverage: 0.6311\n",
            "Iter 800/10000, Train loss: 1.7153, Val loss: 1.7091, Recall: 0.1686, Precision: 0.5194, Gini: 0.8283, Coverage: 0.6311\n",
            "Iter 1000/10000, Train loss: 1.6030, Val loss: 1.5970, Recall: 0.1948, Precision: 0.5440, Gini: 0.8281, Coverage: 0.6311\n",
            "Iter 1200/10000, Train loss: 1.5253, Val loss: 1.5194, Recall: 0.2145, Precision: 0.5607, Gini: 0.8280, Coverage: 0.6311\n",
            "Iter 1400/10000, Train loss: 1.4671, Val loss: 1.4614, Recall: 0.2310, Precision: 0.5751, Gini: 0.8278, Coverage: 0.6311\n",
            "Iter 1600/10000, Train loss: 1.4212, Val loss: 1.4156, Recall: 0.2441, Precision: 0.5828, Gini: 0.8276, Coverage: 0.6311\n",
            "Iter 1800/10000, Train loss: 1.3836, Val loss: 1.3783, Recall: 0.2555, Precision: 0.5905, Gini: 0.8274, Coverage: 0.6311\n",
            "Iter 2000/10000, Train loss: 1.3522, Val loss: 1.3470, Recall: 0.2660, Precision: 0.5992, Gini: 0.8272, Coverage: 0.6314\n",
            "Iter 2200/10000, Train loss: 1.3254, Val loss: 1.3203, Recall: 0.2756, Precision: 0.6072, Gini: 0.8270, Coverage: 0.6317\n",
            "Iter 2400/10000, Train loss: 1.3021, Val loss: 1.2972, Recall: 0.2845, Precision: 0.6144, Gini: 0.8269, Coverage: 0.6317\n",
            "Iter 2600/10000, Train loss: 1.2818, Val loss: 1.2770, Recall: 0.2922, Precision: 0.6212, Gini: 0.8267, Coverage: 0.6317\n",
            "Iter 2800/10000, Train loss: 1.2638, Val loss: 1.2591, Recall: 0.3004, Precision: 0.6259, Gini: 0.8266, Coverage: 0.6314\n",
            "Iter 3000/10000, Train loss: 1.2479, Val loss: 1.2433, Recall: 0.3079, Precision: 0.6320, Gini: 0.8265, Coverage: 0.6314\n",
            "Iter 3200/10000, Train loss: 1.2337, Val loss: 1.2292, Recall: 0.3155, Precision: 0.6370, Gini: 0.8264, Coverage: 0.6314\n",
            "Iter 3400/10000, Train loss: 1.2210, Val loss: 1.2165, Recall: 0.3210, Precision: 0.6407, Gini: 0.8262, Coverage: 0.6317\n",
            "Iter 3600/10000, Train loss: 1.2096, Val loss: 1.2052, Recall: 0.3263, Precision: 0.6433, Gini: 0.8261, Coverage: 0.6317\n",
            "Iter 3800/10000, Train loss: 1.1994, Val loss: 1.1950, Recall: 0.3318, Precision: 0.6471, Gini: 0.8260, Coverage: 0.6317\n",
            "Iter 4000/10000, Train loss: 1.1902, Val loss: 1.1859, Recall: 0.3369, Precision: 0.6502, Gini: 0.8259, Coverage: 0.6314\n",
            "Iter 4200/10000, Train loss: 1.1819, Val loss: 1.1777, Recall: 0.3409, Precision: 0.6524, Gini: 0.8258, Coverage: 0.6314\n",
            "Iter 4400/10000, Train loss: 1.1745, Val loss: 1.1703, Recall: 0.3448, Precision: 0.6550, Gini: 0.8257, Coverage: 0.6314\n",
            "Iter 4600/10000, Train loss: 1.1679, Val loss: 1.1637, Recall: 0.3490, Precision: 0.6574, Gini: 0.8256, Coverage: 0.6311\n",
            "Iter 4800/10000, Train loss: 1.1620, Val loss: 1.1578, Recall: 0.3520, Precision: 0.6602, Gini: 0.8255, Coverage: 0.6311\n",
            "Iter 5000/10000, Train loss: 1.1567, Val loss: 1.1525, Recall: 0.3555, Precision: 0.6636, Gini: 0.8255, Coverage: 0.6311\n",
            "Iter 5200/10000, Train loss: 1.1521, Val loss: 1.1478, Recall: 0.3580, Precision: 0.6652, Gini: 0.8254, Coverage: 0.6317\n",
            "Iter 5400/10000, Train loss: 1.1479, Val loss: 1.1437, Recall: 0.3604, Precision: 0.6672, Gini: 0.8253, Coverage: 0.6319\n",
            "Iter 5600/10000, Train loss: 1.1442, Val loss: 1.1400, Recall: 0.3625, Precision: 0.6687, Gini: 0.8252, Coverage: 0.6322\n",
            "Iter 5800/10000, Train loss: 1.1410, Val loss: 1.1367, Recall: 0.3647, Precision: 0.6703, Gini: 0.8251, Coverage: 0.6322\n",
            "Iter 6000/10000, Train loss: 1.1382, Val loss: 1.1338, Recall: 0.3667, Precision: 0.6709, Gini: 0.8250, Coverage: 0.6325\n",
            "Iter 6200/10000, Train loss: 1.1357, Val loss: 1.1313, Recall: 0.3683, Precision: 0.6718, Gini: 0.8249, Coverage: 0.6325\n",
            "Iter 6400/10000, Train loss: 1.1335, Val loss: 1.1291, Recall: 0.3695, Precision: 0.6729, Gini: 0.8249, Coverage: 0.6325\n",
            "Iter 6600/10000, Train loss: 1.1316, Val loss: 1.1272, Recall: 0.3705, Precision: 0.6739, Gini: 0.8248, Coverage: 0.6325\n",
            "Iter 6800/10000, Train loss: 1.1300, Val loss: 1.1255, Recall: 0.3711, Precision: 0.6741, Gini: 0.8248, Coverage: 0.6325\n",
            "Iter 7000/10000, Train loss: 1.1286, Val loss: 1.1240, Recall: 0.3717, Precision: 0.6743, Gini: 0.8248, Coverage: 0.6325\n",
            "Iter 7200/10000, Train loss: 1.1274, Val loss: 1.1227, Recall: 0.3725, Precision: 0.6749, Gini: 0.8247, Coverage: 0.6325\n",
            "Iter 7400/10000, Train loss: 1.1263, Val loss: 1.1216, Recall: 0.3731, Precision: 0.6753, Gini: 0.8247, Coverage: 0.6325\n",
            "Iter 7600/10000, Train loss: 1.1255, Val loss: 1.1207, Recall: 0.3735, Precision: 0.6752, Gini: 0.8247, Coverage: 0.6325\n",
            "Iter 7800/10000, Train loss: 1.1247, Val loss: 1.1199, Recall: 0.3742, Precision: 0.6758, Gini: 0.8246, Coverage: 0.6325\n",
            "Iter 8000/10000, Train loss: 1.1241, Val loss: 1.1192, Recall: 0.3744, Precision: 0.6758, Gini: 0.8246, Coverage: 0.6325\n",
            "Iter 8200/10000, Train loss: 1.1235, Val loss: 1.1186, Recall: 0.3746, Precision: 0.6761, Gini: 0.8246, Coverage: 0.6325\n",
            "Iter 8400/10000, Train loss: 1.1231, Val loss: 1.1181, Recall: 0.3747, Precision: 0.6763, Gini: 0.8245, Coverage: 0.6325\n",
            "Iter 8600/10000, Train loss: 1.1227, Val loss: 1.1177, Recall: 0.3751, Precision: 0.6764, Gini: 0.8245, Coverage: 0.6325\n",
            "Iter 8800/10000, Train loss: 1.1224, Val loss: 1.1173, Recall: 0.3751, Precision: 0.6762, Gini: 0.8245, Coverage: 0.6325\n",
            "Iter 9000/10000, Train loss: 1.1221, Val loss: 1.1170, Recall: 0.3751, Precision: 0.6761, Gini: 0.8245, Coverage: 0.6325\n",
            "Iter 9200/10000, Train loss: 1.1219, Val loss: 1.1168, Recall: 0.3752, Precision: 0.6763, Gini: 0.8245, Coverage: 0.6325\n",
            "Iter 9400/10000, Train loss: 1.1218, Val loss: 1.1166, Recall: 0.3753, Precision: 0.6763, Gini: 0.8244, Coverage: 0.6325\n",
            "Iter 9600/10000, Train loss: 1.1217, Val loss: 1.1164, Recall: 0.3760, Precision: 0.6767, Gini: 0.8244, Coverage: 0.6325\n",
            "Iter 9800/10000, Train loss: 1.1216, Val loss: 1.1163, Recall: 0.3759, Precision: 0.6768, Gini: 0.8244, Coverage: 0.6325\n"
          ]
        }
      ],
      "source": [
        "for iter in range(ITERATIONS):\n",
        "    # FORWARD PASS\n",
        "    pred_ratings = model(train_edge_index, train_edge_values, num_users, num_movies)\n",
        "    train_loss = loss_function(pred_ratings, r_mat_train_edge_values.view(-1, 1))\n",
        "\n",
        "    # BACKWARD PASS\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # VALIDATION SET\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred_ratings = model(val_edge_index, val_edge_values, num_users, num_movies)\n",
        "            val_loss = loss_function(pred_ratings, r_mat_val_edge_values.view(-1, 1)).sum()\n",
        "\n",
        "            recall, precision, gini, coverage = get_recommendation_metrics(\n",
        "                r_mat_val_edge_index, r_mat_val_edge_values, pred_ratings, num_movies, k=N_ELEMENTS_REC\n",
        "            )\n",
        "            print(\n",
        "                f\"Iter {iter}/{ITERATIONS}, Train loss: {train_loss.item():.4f}, \"\n",
        "                f\"Val loss: {val_loss.item():.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}, Gini: {gini:.4f}, Coverage: {coverage:.4f}\"\n",
        "            )\n",
        "            model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf2e34PecEc5",
        "outputId": "ac34b70b-8ad6-44eb-9afd-bd46c79d8986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test metrics:\n",
            "Loss: 1.1216\n",
            "Recall: 0.3820\n",
            "Precision: 0.6723\n",
            "Gini Index: 0.8212\n",
            "Coverage: 0.6371\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_ratings = model.forward(test_edge_index, test_edge_values, num_users, num_movies)\n",
        "    test_loss = loss_function(pred_ratings, r_mat_test_edge_values.view(-1, 1))\n",
        "    recall, precision, gini, coverage = get_recommendation_metrics(\n",
        "        r_mat_test_edge_index, r_mat_test_edge_values, pred_ratings, num_movies, k=N_ELEMENTS_REC\n",
        "    )\n",
        "    print(f\"Test metrics:\\nLoss: {test_loss.item():.4f}\\nRecall: {recall:.4f}\\n\"\n",
        "          f\"Precision: {precision:.4f}\\nGini Index: {gini:.4f}\\nCoverage: {coverage:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
